{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tgrnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXuoKUbWAYO7",
        "outputId": "e53b0947-6d64-4905-a27e-997ef9a0db8a"
      },
      "source": [
        "!pip install pyarrow==2.0.0\r\n",
        "!pip install git+https://github.com/minimaxir/textgenrnn.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyarrow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 205kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow==2.0.0) (1.19.4)\n",
            "Installing collected packages: pyarrow\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed pyarrow-2.0.0\n",
            "Collecting git+https://github.com/minimaxir/textgenrnn.git\n",
            "  Cloning https://github.com/minimaxir/textgenrnn.git to /tmp/pip-req-build-2is8glc5\n",
            "  Running command git clone -q https://github.com/minimaxir/textgenrnn.git /tmp/pip-req-build-2is8glc5\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from textgenrnn==2.0.0) (2.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from textgenrnn==2.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from textgenrnn==2.0.0) (4.41.1)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from textgenrnn==2.0.0) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py->textgenrnn==2.0.0) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->textgenrnn==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->textgenrnn==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->textgenrnn==2.0.0) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.32.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.1.0->textgenrnn==2.0.0) (51.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.4.0)\n",
            "Building wheels for collected packages: textgenrnn\n",
            "  Building wheel for textgenrnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textgenrnn: filename=textgenrnn-2.0.0-cp36-none-any.whl size=1734418 sha256=a38a379a46c412c66c718f91b326b61e3264d391e1947960e8979aecdeeccbaa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lcpwo57h/wheels/65/ee/bd/b3bd6d3d84e916279b403b1d83d6a6a820d0b47226ad92bc97\n",
            "Successfully built textgenrnn\n",
            "Installing collected packages: textgenrnn\n",
            "  Found existing installation: textgenrnn 1.4.1\n",
            "    Uninstalling textgenrnn-1.4.1:\n",
            "      Successfully uninstalled textgenrnn-1.4.1\n",
            "Successfully installed textgenrnn-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ItLOWfUc06W",
        "outputId": "b51288c5-0d81-4412-a4d8-de299933c082"
      },
      "source": [
        "!pip install pygithub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygithub\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/44/df78514f2b5f5abaec330596e0fa3273824238399a964d1a7e82fd39990d/PyGithub-1.54.1-py3-none-any.whl (289kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 26.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 33.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30kB 38.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 40kB 40.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 81kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 92kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 102kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 112kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 122kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 133kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 143kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 153kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 163kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 174kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 184kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 194kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 204kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 215kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 225kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 235kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 245kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 256kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 266kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 276kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 286kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 14.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.6/dist-packages (from pygithub) (2.23.0)\n",
            "Collecting pyjwt<2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
            "Collecting deprecated\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->pygithub) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->pygithub) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->pygithub) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->pygithub) (3.0.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated->pygithub) (1.12.1)\n",
            "Installing collected packages: pyjwt, deprecated, pygithub\n",
            "Successfully installed deprecated-1.2.10 pygithub-1.54.1 pyjwt-1.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3jtgGyXA_iw"
      },
      "source": [
        "import pandas as pd\r\n",
        "import time\r\n",
        "from github import Github"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04E5fO_tdAYS"
      },
      "source": [
        "github = Github(\"aefcbe45583e1ee87ddea62bad904e4b095d1455\")\r\n",
        "def push(repo_path, file_path):\r\n",
        "  filename = f\"{time.time():.0f}.{file_path.split('.')[-1]}\"\r\n",
        "  github.get_repo('Scytheface/NARV').create_file(f\"{repo_path}{filename}\",\r\n",
        "                   requests.get('http://whatthecommit.com/index.txt').text.strip(),\r\n",
        "                   open(file_path, 'rb').read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHgyRAt9AtOm"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\r\n",
        "    import tensorflow as tf\r\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)\r\n",
        "else:\r\n",
        "    import contextlib\r\n",
        "    strategy = type(\"\", (), {'scope': contextlib.suppress})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYC5Twg5A17G"
      },
      "source": [
        "import requests\r\n",
        "data = pd.read_feather('https://github.com/Scytheface/NARV/raw/main/lyrics/lyrics.ft')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qcuM7piDBS3g",
        "outputId": "94905a9b-e786-48a7-d5e4-72130ffcd231"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>title</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dvph</td>\n",
              "      <td>punased käed</td>\n",
              "      <td>[Intro]\\nKes seal on?\\n\\n[Verse 1]\\nDVPH - see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mõmmi</td>\n",
              "      <td>modellid</td>\n",
              "      <td>(HOOK: MÕMMI)\\nKallid rõivad\\nNeed on seljas\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mõmmi</td>\n",
              "      <td>meeldib</td>\n",
              "      <td>[HOOK; MÕMMI]\\nTalle meeldib playboy\\nRanne jä...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mõmmi</td>\n",
              "      <td>mukehamavõpatan</td>\n",
              "      <td>Luuad pakule, makule meeldib\\nJoogid ju valatu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nublu</td>\n",
              "      <td>für oksana</td>\n",
              "      <td>А это жизнь, это карма\\nЭй, привет, город Нарв...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  artist            title                                             lyrics\n",
              "0   dvph     punased käed  [Intro]\\nKes seal on?\\n\\n[Verse 1]\\nDVPH - see...\n",
              "1  mõmmi         modellid  (HOOK: MÕMMI)\\nKallid rõivad\\nNeed on seljas\\n...\n",
              "2  mõmmi          meeldib  [HOOK; MÕMMI]\\nTalle meeldib playboy\\nRanne jä...\n",
              "3  mõmmi  mukehamavõpatan  Luuad pakule, makule meeldib\\nJoogid ju valatu...\n",
              "4  nublu       für oksana  А это жизнь, это карма\\nЭй, привет, город Нарв..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3YIhE3xBHtd"
      },
      "source": [
        "texts = []\r\n",
        "for _, row in data.iterrows():\r\n",
        "  if row['lyrics']:\r\n",
        "    texts.append(row['lyrics'].lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "M3IyhecwBxh6",
        "outputId": "ca24d4df-53d4-4e8e-b68f-dbba5400b4f3"
      },
      "source": [
        "  from textgenrnn import textgenrnn\r\n",
        "\r\n",
        "  model_cfg = {\r\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\r\n",
        "    'rnn_size': 256,   # number of LSTM cells of each layer (128/256 recommended)\r\n",
        "    'rnn_layers': 5,   # number of LSTM layers (>=2 recommended)\r\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\r\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\r\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\r\n",
        "  }\r\n",
        "\r\n",
        "  train_cfg = {\r\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\r\n",
        "    'num_epochs': 100,   # set higher to train the model for longer\r\n",
        "    'gen_epochs': 100,   # generates sample text from model after given number of epochs\r\n",
        "    'train_size': 1,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\r\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\r\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\r\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\r\n",
        "  }\r\n",
        "\r\n",
        "  textgen = textgenrnn(name='tgrnn')\r\n",
        "  \r\n",
        "  textgen.train_on_texts(\r\n",
        "      save_epochs=1,\r\n",
        "    texts=texts,\r\n",
        "    new_model=True,\r\n",
        "    num_epochs=train_cfg['num_epochs'],\r\n",
        "    gen_epochs=train_cfg['gen_epochs'],\r\n",
        "    batch_size=1024,\r\n",
        "    train_size=train_cfg['train_size'],\r\n",
        "    dropout=train_cfg['dropout'],\r\n",
        "    validation=train_cfg['validation'],\r\n",
        "    is_csv=train_cfg['is_csv'],\r\n",
        "    rnn_layers=model_cfg['rnn_layers'],\r\n",
        "    rnn_size=model_cfg['rnn_size'],\r\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\r\n",
        "    max_length=model_cfg['max_length'],\r\n",
        "    dim_embeddings=100,\r\n",
        "    word_level=model_cfg['word_level'])\r\n",
        "  textgen.save('rapmodel.hdf5')\r\n",
        "  #push('models/', 'rapmodel.hdf5')  \r\n",
        "  #push('models/', 'tgrnn_weights_epoch_200.hdf5') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training new model w/ 5-layer, 256-cell LSTMs\n",
            "Training on 1,783,307 character sequences.\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dea1536d2c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mdim_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   word_level=model_cfg['word_level'])\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mtextgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rapmodel.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#push('models/', 'rapmodel.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_on_texts\u001b[0;34m(self, texts, context_labels, batch_size, num_epochs, verbose, new_model, gen_epochs, train_size, max_gen_length, validation, dropout, via_new_model, save_epochs, multi_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0msave_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                                  \u001b[0mmulti_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                                  **kwargs)\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_new_model\u001b[0;34m(self, texts, context_labels, num_epochs, gen_epochs, batch_size, dropout, train_size, validation, save_epochs, multi_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             \u001b[0msave_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                             \u001b[0mmulti_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"textgenrnn_weights_saved.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_on_texts\u001b[0;34m(self, texts, context_labels, batch_size, num_epochs, verbose, new_model, gen_epochs, train_size, max_gen_length, validation, dropout, via_new_model, save_epochs, multi_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                               \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                               )\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aii9NS63EWd_"
      },
      "source": [
        "from textgenrnn import textgenrnn\r\n",
        "tg = textgenrnn(config_path='tgrnn_config.json', weights_path='tgrnn_weights_epoch_30.hdf5', vocab_path='tgrnn_vocab.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTlJV-eRvzNS",
        "outputId": "43c91eb2-995c-4d2a-bf35-32985489d313"
      },
      "source": [
        "tg.generate(5, max_gen_length=1000\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [00:04<00:17,  4.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ta tahtis teada ma viga . \n",
            " \n",
            " ikka ju näen , et ka silmast ja su ema omaje tead ma sain , \n",
            " kuid miski pillumist ja raudne kopp \n",
            " oi king kong ! \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [00:34<00:36, 12.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " [ intro ] \n",
            " rahabos ja ma ei tea ta minu hoolekult on su kõrval \n",
            " sinu jaoks on see tšort \n",
            " see on paradoks kui narko surma tipp ajab riip \n",
            " sa ei saa , mul kanal ei tee \n",
            " aga tegelt ei saa \n",
            " \n",
            " sa arvad kõik saab korda , \n",
            " nii ma arvasin ka \n",
            " sa arvad kõik saab korda , \n",
            " aga tegelt ei saa \n",
            " \n",
            " sa arvad kõik saab korda , \n",
            " aga tegelt ei saa \n",
            " \n",
            " sa arvad kõik saab korda , \n",
            " aga tegelt ei saa \n",
            " \n",
            " sa arvad kõik saab korda , üle sõita neiu \n",
            " sest mu emme vaikselt armastan . \n",
            " ma ei saa kunagi tungita lasta \n",
            " ta tagaini seitse vana \n",
            " naabrib kürjaks minu seljas , jook jeesus \n",
            " tõsta klubis näinud , natukene veel \n",
            " ja ma ei armasta mind ja mingi perse ! \n",
            " kuhu tee kutsun ta \n",
            " \n",
            " [ outro ] \n",
            " võit - ja ( võidan viite ) \n",
            " su nie [ ? ] , sul on suva all , juba ma palun andma \n",
            " andke kohe mitte midagi teha \n",
            " ma ei oska kaine peaga peol mitte midagi teha \n",
            " ma ei saa sinu vastast enam mitte üksi \n",
            " kuid ma pole lihtsalt pätt tindida \n",
            " siin mängus saadab kõik mis ma läbi aknast \n",
            " \n",
            " [ chorus ] \n",
            " kui me\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [01:05<00:35, 17.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "jou ja me autos \n",
            " sa tead seda enne kui telefoni \n",
            " su libe kajab , aasta oma tööpäeva lõpuks ühest pole huvi \n",
            " sinu südames on mu ununes \n",
            " sa ei saagi aru \n",
            " ja kõik on üks dark , kas õpetaja peidab nagu tarkust \n",
            " naabris elus suvel näeb \n",
            " kus käis on , seepilk ja see tähtis on meil sihin pikikuthev . \n",
            " siin on kõike piisavalt , a sellest ei piisa . \n",
            " limpsab alati uue järgi keelt . \n",
            " liigsed valikud teevad ju liiga , \n",
            " alistades siis see on \n",
            " võõraste seleta \n",
            " kuid ainult seal bansivad koolid \n",
            " \n",
            " [ bridge : mard ] \n",
            " kolm koma on sulle täpselt nii \n",
            " sorry , et maa on tunne , \n",
            " nagu me enda tulemast \n",
            " \n",
            " beebilõust : \n",
            " mu singel ei valluta ees , et tervika kallim mu meeles \n",
            " sa tahad tasa dype ' s ongi gramm \n",
            " lõpp on koksi siis nõme - lits kony \n",
            " kätte lasen lahti ja kõigil on juppe \n",
            " teen kõik asjadel astudes \n",
            " ei tea mitu valmis hoopis \n",
            " olen legendam rahutust läheb , \n",
            " oma austu jälle nullis ! \n",
            " \n",
            " “ mis saab siis ? \n",
            " \n",
            " ma olen hustlik , oled parim , parem ja parem \n",
            " ja kui sa vambis \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [01:35<00:21, 21.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ma elad söögin sinu imidokki \n",
            " see on kantra \n",
            " mu pasa miks sa magad mind maha \n",
            " ei taha kedo maha kõik kes vaid vaabab \n",
            " kui sulle ei meeldi sinusugust pole vaja \n",
            " oma eluluhule andestage kui ta liha teed \n",
            " mõtlen sind ja mina jään \n",
            " veel üks peer \n",
            " võtan viin ma \n",
            " küllast unusta , mis asoonikuud ? \n",
            " kaks vastupidi nagu oleks libistamist \n",
            " mõned kui tuules see on ju õige \n",
            " \n",
            " [ verse 3 ] \n",
            " kui  teada sama palju tagasi ma saan \n",
            " kuid nii ma pole tahtnud \n",
            " kikivarvul kõnnin ümber palava pudru \n",
            " nii ma , nii ma astun , \n",
            " kuid nii ma pole tahtnud \n",
            " kümned näed , et \n",
            " sa jääd ka veel \n",
            " kahe käia võiks vahest karjub \n",
            " minut mõtlen aint sulle fakting läbi \n",
            " mu kütted , ma tulen ja tunnen nagu inimese \n",
            " ja kuula mu nime - sinu kohta \n",
            " päikse lähen vahel palju on hea \n",
            " see on feik , ei ole alistu \n",
            " olen paitsnud kes see paneb emotsioon \n",
            " kui ma kuulen sind naine nagu ma ja ma kannan su eluga \n",
            " kus on minu sõnu \n",
            " seest kas midagi muud , kuid see on jumala eos \n",
            " \n",
            " 2 . kõik on nii , et mis siin \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [02:06<00:00, 25.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "jou , ma loome loomist \n",
            " kuidas kullid on siia \n",
            " \n",
            " [ chorus ] \n",
            " ja - a - a - a \n",
            " ja - a - a - a - a - a - a - a - a - a - a - a \n",
            " ja - aa - a - jaa , \n",
            " \n",
            " jaja \n",
            " igar m maja , su sebi on mu pane julge \n",
            " \n",
            " verse : ees ja ma pole sees \n",
            " \n",
            " sa tõid ju kodus ja kaotus \n",
            " sinu jaoks ta näljane \n",
            " maga on üks minu teine nagu ma teind \n",
            " elu pole aega , ainus asi kus mu meli \n",
            " särab nii kaua kuni on sees , \n",
            " ei tunne end kui õpetand , kuid tead mida teed hulluks \n",
            " mind ei huvita kummer , näed välja mul ajal , \n",
            " kui palju sõnu . ma tahan rebele \n",
            " sest keelduda raha , miski wppeck on ? \n",
            " su vingu ona taga , lase ma armastan \n",
            " rohenika ja suvepäev saadik saan ma oma maale \n",
            " mul on meil plaan , hull minna ? \n",
            " see venekski sinu kund on niimoodi \n",
            " ei saa jätkata \n",
            " neid asju ette \n",
            " kuigi hellad või hoopis tuleb \n",
            " ja nagu jeeli ta leiab , just saab kuis said \n",
            " mind valusad toimunud , nad kokkuvalged \n",
            " see valksteel liialt minek ka piisavalt \n",
            " siis ma kaddata saan kõik külast , kõik on juba praegu tarkus \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}